{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zangatec/4055_team50/blob/main/TC5033_Activity1b_Team50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpFbDR2bhuR0"
      },
      "source": [
        "# TC 5033\n",
        "## Deep Learning\n",
        "## Fully Connected Deep Neural Networks\n",
        "\n",
        "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
        "\n",
        "- Objective\n",
        "\n",
        "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
        "\n",
        "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
        "\n",
        "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
        "\n",
        "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
        "    \n",
        "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
        "\n",
        "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
        "\n",
        "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
        "\n",
        "- Evaluation Criteria\n",
        "\n",
        "    - Code Readability and Comments\n",
        "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
        "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
        "    - Quality of Markdown documentation\n",
        "\n",
        "- Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LpUgJisKhuR3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "#################################\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D7fg1IFn_lV",
        "outputId": "5e7a86b1-4023-48f1-c772-9063607da4fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uif_lUq6huR4"
      },
      "outputs": [],
      "source": [
        "# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
        "#DATA_PATH = 'https://drive.google.com/file/d/168t4kGtYDeN3UPaNe1Y2I5Sr2L73U8rc/uc?export=download'\n",
        "DATA_PATH = '/content/drive/MyDrive/asl_data'\n",
        "#!gdown --id 1xq6ez1e8vglBICODubGMj2nCWY8JxLjj\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
        "\n",
        "#!gdown --id 13sr3YyN8JlLenDguxUgHYSghUiCgZ7Iz\n",
        "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pkzk_1pvhuR4",
        "outputId": "8cd5ede1-98fb-403c-e796-2b7bac34951d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     12     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d5f2306-fe7a-40a1-83a3-3c58c4b61109\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d5f2306-fe7a-40a1-83a3-3c58c4b61109')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1d5f2306-fe7a-40a1-83a3-3c58c4b61109 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1d5f2306-fe7a-40a1-83a3-3c58c4b61109');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29c144ac-31af-4797-9f74-82ae3832370a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29c144ac-31af-4797-9f74-82ae3832370a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29c144ac-31af-4797-9f74-82ae3832370a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyGAQpXWhuR4"
      },
      "source": [
        "### Importar Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nd4Pc7F9huR4"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_df['label'])               #Label indicates the y value\n",
        "y_val = np.array(valid_df['label'])                 #Label indicates the y value\n",
        "del train_df['label']                               #For the image pixels we don't require the y\n",
        "del valid_df['label']                               #For the image pixels we don't require the y\n",
        "x_train = train_df.values.astype(np.float32)\n",
        "x_val = valid_df.values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "code_folding": [],
        "id": "EwIsv1NXhuR4"
      },
      "outputs": [],
      "source": [
        "# In this section we define the split, for this we decided to just split the data based on an index predefined by the pct. Allthough there is a shuffle, given that we have no previous information, we assume the images are already shuffled.\n",
        "\n",
        "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
        "    split_index = int(len(x) * pct)\n",
        "    x_val = x[split_index:]\n",
        "    y_val = y[split_index:]\n",
        "\n",
        "    x_test = x[:split_index]\n",
        "    y_test = y[:split_index]\n",
        "    return x_val, y_val, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M6O6qS8HhuR4"
      },
      "outputs": [],
      "source": [
        "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "-2px6s2R0V1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ug9BTR15huR5"
      },
      "outputs": [],
      "source": [
        "# Normalization function to improve results, given that NN work better with normalized data\n",
        "def normalise(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std\n",
        "\n",
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "# Here it is important to note that all data is being scaled using the training data mean and standard deviation in order to avoid contamination.\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Xqh8o8-3huR5",
        "outputId": "a77f8c33-1915-4600-c52b-97a2b99db41b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "### The following just inports the alphabet.\n",
        "\n",
        "alphabet=list(string.ascii_lowercase)\n",
        "alphabet.remove('j')\n",
        "alphabet.remove('z')\n",
        "print(len(alphabet))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Samples.\n",
        " Since there are 784 columns + label. We have a 28x28 pixel image.\n",
        ""
      ],
      "metadata": {
        "id": "S81o6iW41m8f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yw2YRathuR5"
      },
      "source": [
        "### Graficar muestras"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SIBjfflC0cMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQtG1Qk0huR5"
      },
      "source": [
        "### Ecuaciones para nuestro modelo\n",
        "\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5F-pV_huR5"
      },
      "source": [
        "### Funciones adicionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDUxCKa7huR5"
      },
      "source": [
        "#### Mini batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk7nAof7huR5"
      },
      "outputs": [],
      "source": [
        "#The creation of mini batches is usually done to increase training speed as the algorighm looks into smaller sample sizes that are less resource intensive.\n",
        "\n",
        "def create_minibatches(mb_size, x, y,shuffle = True):\n",
        "\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0]\n",
        "    if shuffle:\n",
        "        idxs = np.arange(total_data)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]\n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVVVF4yZhuR5",
        "outputId": "512d6551-5498-452b-c76d-adc13b49bfbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class np_tensor(np.ndarray): pass   #This allows us to create atributes to the np_tensor which is an array later on\n",
        "\n",
        "a = np.array([0, 0])\n",
        "b = a.view(np_tensor)\n",
        "type(a)\n",
        "type(b)\n",
        "a == b\n",
        "a is b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awl0AF1-huR5"
      },
      "source": [
        "## Nuestra clase Linear, ReLU y Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uumE6iGHhuR6"
      },
      "source": [
        "###  Clase Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2DRJcrxhuR6"
      },
      "outputs": [],
      "source": [
        "class Linear():\n",
        "    def __init__(self, input_size, output_size):                                                        #This is the initialization of the function, input_size is the amount of elements in the previous layer, output size is the amount of neurons defined for this layer.\n",
        "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)     #Define random weights as a startin point based on Kaiming He, where the weights are based on the current and previous layers amount of neurons.\n",
        "        self.b = (np.zeros((output_size, 1))).view(np_tensor)                                           # Initiates as zeroes in one column\n",
        "    def __call__(self, X):                                                                              # Forward pass\n",
        "        Z = self.W @ X + self.b                                                                         # This equals to Wx+b\n",
        "        return Z\n",
        "\n",
        "    def backward(self, X, Z):                                                                           #Backward pass, X is the # of entrances, Z the # of outputs\n",
        "        X.grad = self.W.T @ Z.grad                                                                      # Gradient X is The gradient times the Weights (Weights are transposed to comply with matrix multiplication)\n",
        "        self.W.grad = Z.grad @ X.T                                                                      # Gradient for the Weights\n",
        "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)                                           # Gradient for the bias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOu-jGmhhuR6"
      },
      "source": [
        "### Clase ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD3vFaLbhuR6"
      },
      "outputs": [],
      "source": [
        "class ReLU():\n",
        "    def __call__(self, Z):              #We obtain Z which is the result of Wx+b\n",
        "        return np.maximum(0, Z)         # What ever Z value is bellow 0 we have a 0 and if the value is bigger than 0 it will as as is.\n",
        "    def backward(self, Z, A):\n",
        "        Z.grad = A.grad.copy()          #we copy the gradient of A to Z\n",
        "        Z.grad[Z <= 0] = 0              # We check if the values are bellow or above 0, if it is bellow zero, the value is 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtWT7zgmhuR6"
      },
      "source": [
        "### Clase Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjE3ERYJhuR6"
      },
      "outputs": [],
      "source": [
        "class Sequential_layers():\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers                                                                    # Here we have the amount of layers\n",
        "        self.x = None                                                                           # x stores all the z value activations of the neurons (It is kind of a ram memory)\n",
        "        self.outputs = {}                                                                       # This dictionaries stores the activations to later calculate backward pass (Kind of a ROM memory)\n",
        "    def __call__(self, X):\n",
        "        self.x = X\n",
        "        self.outputs['l0'] = self.x                                                             # The first elements are the inputs\n",
        "        for i, layer in enumerate(self.layers, 1):                                              # For loop where we go through all the layers inside, either Linear, Relu or what ever you have defined before\n",
        "            self.x = layer(self.x)\n",
        "            self.outputs['l'+str(i)]=self.x                                                     # Save elements in outputs\n",
        "        return self.x\n",
        "    def backward(self):                                                                         # Enables backward pass\n",
        "        for i in reversed(range(len(self.layers))):                                             # Loops through all the layers on a backward sequence\n",
        "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])       # On the first part we store the outputs of the current layer and then the outputs of the previous layer\n",
        "    def update(self, learning_rate = 1e-3):\n",
        "        for layer in self.layers:                                                               # Loop that helps us go through all the layers\n",
        "            if isinstance(layer, ReLU): continue                                                # Since Relu doesn't have tunable parameters we can omit it with this if\n",
        "            layer.W = layer.W - learning_rate * layer.W.grad                                    # We call the current W weight and then reduce it by the W gradient times the learning rate.\n",
        "            layer.b = layer.b - learning_rate * layer.b.grad                                    # We call the current b bias and then reduce it by the b gradient times the learning rate.\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.__call__(X))                                                      # Returns the index with the highest scores (Final Predicted y value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbZppcQ3huR6"
      },
      "source": [
        "### Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ4oJ0jRhuR6"
      },
      "outputs": [],
      "source": [
        "def softmaxXEntropy(x, y):\n",
        "    batch_size = x.shape[1]                             # Gets the size\n",
        "    exp_scores = np.exp(x)                              # gets the scores\n",
        "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
        "    preds = probs.copy()\n",
        "    # Costo\n",
        "    y_hat = probs[y.squeeze(), np.arange(batch_size)]   #Gets the scores\n",
        "    cost = np.sum(-np.log(y_hat)) / batch_size          #Calculate the costs  by getting the logarithm of the preduction over the batch size\n",
        "    # Calcular gradientes\n",
        "    probs[y.squeeze(), np.arange(batch_size)] -= 1      #For all the correct values we substract a 1 due to yhat-y\n",
        "    x.grad = probs.copy()\n",
        "\n",
        "    return preds, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZDsMlEGhuR6"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFV5IR__huR6"
      },
      "outputs": [],
      "source": [
        "def accuracy(x, y, mb_size):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):      # Cicle through the mini batches\n",
        "        pred = model(x.T.view(np_tensor))\n",
        "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())       # Add 1 for all the predicted values that are correct\n",
        "        total += pred.shape[1]                                          # Count all the values\n",
        "    return correct/total                                                # Divide correct values over all the values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8GkX4TnhuR6"
      },
      "source": [
        "### Loop de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3KgXralhuR6"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
        "    for epoch in range(epochs):                                                                 # Loop that goes through epochs\n",
        "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):              # We define minibatch size as mb_size, X values and y values and run through all the mini batches\n",
        "            scores = model(x.T.view(np_tensor))                                                 # we require to pass x values as a tensor so that it gets stored for gradient calculation\n",
        "            _, cost = softmaxXEntropy(scores, y)                                                # Run the cost portion\n",
        "            model.backward()                                                                    # Run the backward portion\n",
        "            model.update(learning_rate)                                                         # Run the learning rate where values are adjusted accordingly\n",
        "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')                    # Print the current cost and accuracy of the model for a quick assesment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55zvr3IMhuR6"
      },
      "source": [
        "### Create your model and train it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cee2oz0lhuR6",
        "outputId": "2cb951c7-018a-4155-8b0c-f28d7c27e817"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index 15 is out of bounds for axis 0 with size 10",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[79], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m\n\u001b[0;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmb_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[78], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, mb_size, learning_rate)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(create_minibatches(mb_size, x_train, y_train)):              \u001b[38;5;66;03m# We define minibatch size as mb_size, X values and y values and run through all the mini batches\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m model(x\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mview(np_tensor))                                                 \u001b[38;5;66;03m# we require to pass x values as a tensor so that it gets stored for gradient calculation\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     _, cost \u001b[38;5;241m=\u001b[39m \u001b[43msoftmaxXEntropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m                                                \u001b[38;5;66;03m# Run the cost portion\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     model\u001b[38;5;241m.\u001b[39mbackward()                                                                    \u001b[38;5;66;03m# Run the backward portion\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate(learning_rate)                                                         \u001b[38;5;66;03m# Run the learning rate where values are adjusted accordingly\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[76], line 7\u001b[0m, in \u001b[0;36msoftmaxXEntropy\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      5\u001b[0m preds \u001b[38;5;241m=\u001b[39m probs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Costo\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mprobs\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m   \u001b[38;5;66;03m#Gets the scores\u001b[39;00m\n\u001b[0;32m      8\u001b[0m cost \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(y_hat)) \u001b[38;5;241m/\u001b[39m batch_size          \u001b[38;5;66;03m#Calculate the costs  by getting the logarithm of the preduction over the batch size\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Calcular gradientes\u001b[39;00m\n",
            "\u001b[1;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 10"
          ]
        }
      ],
      "source": [
        "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
        "mb_size = 15\n",
        "learning_rate = 1e-3\n",
        "epochs = 50\n",
        "\n",
        "train(model, epochs, mb_size, learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnII1tXKhuR6"
      },
      "source": [
        "### Test your model on Random data from your test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymm8qizbhuR6",
        "outputId": "662d3ebb-8b5e-4800-f5bf-45780905c428"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plot_number' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mlen\u001b[39m(y_test))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplot_number\u001b[49m(x_test[idx]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test[idx]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mel valor predicho es: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphabet[pred]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m el valor real es:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malphabet[y_test[idx]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'plot_number' is not defined"
          ]
        }
      ],
      "source": [
        "idx = np.random.randint(len(y_test))\n",
        "plot_number(x_test[idx].reshape(28,28))\n",
        "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
        "print(f'el valor predicho es: {alphabet[pred]} el valor real es:{alphabet[y_test[idx]]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4YMBlnihuR6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}